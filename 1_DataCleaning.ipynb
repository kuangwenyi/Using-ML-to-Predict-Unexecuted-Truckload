{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import boto3\n",
    "import gc\n",
    "import random\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from io import StringIO\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/Desktop/Classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_STATES = ['AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA','MI','MN','MS','MO','MT',\n",
    "'NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY']\n",
    "\n",
    "US_REGIONS = ['MW', 'NE', 'NW', 'SE', 'SW', 'TX', 'UNKNOWN']\n",
    "\n",
    "CUSTOMER_FACING = ['Y','N']\n",
    "TRANSIT_OPERATORS =['SINGLE_DRIVER', 'TEAM_DRIVER']\n",
    "\n",
    "DRIVER_TYPE = ['TEAM','SOLO1','SOLO2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = pd.read_csv(data_dir + 'loads-Training.txt',sep = \"\\t\" )\n",
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(loads[loads['transit_operator_type'] == 'TEAM_DRIVER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads[loads.average_transit_hour > 690])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(loads.load_id.unique()) == len(loads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(loads.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = loads[~loads.origin.isnull()]\n",
    "loads = loads[~loads.final_destination.isnull()]\n",
    "loads = loads[~loads.origin_zip.isnull()]\n",
    "loads = loads[~loads.dest_zip.isnull()]\n",
    "loads = loads[~loads.origin_state.isnull()]\n",
    "loads = loads[~loads.dest_state.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lane(row):\n",
    "    lane = row['origin'] + '->' + row['final_destination']\n",
    "    return lane\n",
    "loads['lane'] = loads.apply(get_lane,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loads.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = loads[loads['checkin_time_windows_at_origin'] >= 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = loads[~loads.creation_date.isnull()]\n",
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['same_origin'] = np.where(loads['planning_origin'] == loads['origin'],1,0)\n",
    "\n",
    "loads = loads[loads.same_origin == 1]\n",
    "\n",
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['same_dest'] = np.where(loads['planning_dest'] == loads['final_destination'],1,0)\n",
    "\n",
    "loads = loads[loads.same_dest == 1]\n",
    "\n",
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(loads.transit_operator_type.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = pd.read_csv(data_dir + 'Blocks-Training.txt',sep='\\t')\n",
    "blocks.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks['startwindowlowerbound'] = pd.to_datetime(blocks['startwindowlowerbound'])\n",
    "blocks['block_end_utc'] = pd.to_datetime(blocks['block_end_utc'])\n",
    "blocks['createddate'] = pd.to_datetime(blocks['createddate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warehouse and Zip Code Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['origin_zip'] = loads['origin_zip'].astype(str)\n",
    "loads['origin_zip'] = loads['origin_zip'].apply(lambda x: x.zfill(5))\n",
    "\n",
    "\n",
    "domiciles_to_main_zip = pd.read_csv(data_dir + 'domiciles_to_main_zip.csv', sep = '\\t')\n",
    "\n",
    "domiciles_to_main_zip['main_zip']  = domiciles_to_main_zip['main_zip'].astype(str)\n",
    "domiciles_to_main_zip['main_zip'] = domiciles_to_main_zip['main_zip'].apply(lambda x: x.zfill(5))\n",
    "domiciles_to_main_zip = domiciles_to_main_zip.rename(columns ={'main_zip':'origin_zip'})\n",
    "\n",
    "\n",
    "print(len(loads))\n",
    "loads = pd.merge(loads,domiciles_to_main_zip,on = 'origin_zip',how='left')\n",
    "print(len(loads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domiciles_to_main_zip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.domicile = loads.domicile.fillna('missing_domicile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domiciles = pd.read_csv(data_dir + 'domicile_to_fc_mapping.csv', sep =',')\n",
    "\n",
    "def replace_str(row):\n",
    "    temp = row['all_fullfilment'].replace('[','')\n",
    "    temp = temp.replace(']','')\n",
    "    temp = temp.replace('\\\"','')\n",
    "    temp = temp.replace('\\\\','')\n",
    "    temp  = temp.split(',')\n",
    "    return temp\n",
    "\n",
    "domiciles['facilities'] = domiciles.apply(lambda row : replace_str(row),axis=1)\n",
    "domiciles = domiciles[['domicile_code','facilities']]\n",
    "domiciles = domiciles.set_index('domicile_code').to_dict()\n",
    "domiciles = domiciles['facilities'].copy()\n",
    "\n",
    "\n",
    "domiciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_domiciles = defaultdict(set) # key: fc values : list of domiciles \n",
    "\n",
    "for domicile,fc_list in domiciles.items():\n",
    "    for fc in fc_list:\n",
    "        fc_domiciles[fc].add(domicile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.origin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_domiciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_timestamp_to_int(ts):\n",
    "    return int(time.mktime(ts.timetuple()))\n",
    "\n",
    "def int_to_pd_timestamp(t):\n",
    "    return pd.Timestamp(t, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by lead time\n",
    "loads['first_checkin_time_utc'] = pd.to_datetime(loads['first_checkin_time_utc'])\n",
    "def loads_pd_timestamp_to_int(row):\n",
    "    ts = row['first_checkin_time_utc']\n",
    "    return int(time.mktime(ts.timetuple()))\n",
    "\n",
    "loads['creation_date_int'] = loads.apply(lambda row: loads_pd_timestamp_to_int(row),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['domicile','startwindowlowerbound','block_end_utc','createddate','blocklength_minutes']   \n",
    "blocks_to_aggregate = blocks[cols].copy()\n",
    "\n",
    "\n",
    "block_tuples = [tuple(x) for x in blocks_to_aggregate.to_numpy()]\n",
    "\n",
    "blocks_dict = defaultdict(list)\n",
    "\n",
    "for (domicile,start,end,creation,block_length) in block_tuples:\n",
    "    blocks_dict[domicile].append([pd_timestamp_to_int(start),pd_timestamp_to_int(end),pd_timestamp_to_int(creation),block_length])\n",
    "\n",
    "new_blocks_dict = {}\n",
    "for key, values in blocks_dict.items():\n",
    "    new_blocks_dict[key] =  np.array(values)\n",
    "blocks_dict = new_blocks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['first_checkin_time_utc'] = pd.to_datetime(loads['first_checkin_time_utc'])\n",
    "# estimated earliest arrival time back to origin  : first check-in time at origin + average transit hours\n",
    "loads['earliest_arrival_time'] = loads.apply(lambda row :row['first_checkin_time_utc'] + 2*datetime.timedelta(seconds=(row['average_transit_hour'])*60),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads[['first_checkin_time_utc','earliest_arrival_time','average_transit_hour','transit_operator_type']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['load_id','origin','first_checkin_time_utc','earliest_arrival_time','creation_date_int','domicile']\n",
    "loads_tuples =  [tuple(x) for x in loads[cols].to_numpy()]\n",
    "len(loads_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.domicile.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_domiciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_dict = {}\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "creation_failed = 0\n",
    "end_failed = 0\n",
    "start_failed = 0\n",
    "total = 0\n",
    "\n",
    "num_loads_without_domicile = 0 \n",
    "loads_without_domicile = set()\n",
    "\n",
    "for (l_id,l_o,l_start,l_end,l_p_cycle,l_dom) in loads_tuples:\n",
    "        \n",
    "    if l_o not in fc_domiciles and l_dom == 'missing_domicile':\n",
    "        loads_dict[(l_id,l_p_cycle)] = (0,0)\n",
    "        num_loads_without_domicile += 1\n",
    "        loads_without_domicile.add(l_id)\n",
    "\n",
    "    else:\n",
    "        num_feasible_blocks = 0\n",
    "        total_block_duration_length = 0\n",
    "        \n",
    "        l_start_int = pd_timestamp_to_int(l_start)\n",
    "        l_end_int = pd_timestamp_to_int(l_end)\n",
    "        \n",
    "        # First check main_zip to domicile\n",
    "        if l_dom != 'missing_domicile': \n",
    "            if l_dom in blocks_dict:\n",
    "                a = blocks_dict[l_dom]\n",
    "                temp_a = a[((a[:,0] ) <= (l_start_int)) & ((a[:, 1]) >= (l_end_int)) & (a[:, 2] <= l_p_cycle)] \n",
    "\n",
    "                num_feasible_blocks = len(temp_a)\n",
    "                total_block_duration_length += sum(temp_a[:,3])\n",
    "            else: \n",
    "                if l_o in fc_domiciles: \n",
    "                    for domicile in fc_domiciles[l_o]:\n",
    "                        if domicile in blocks_dict:\n",
    "                            a = blocks_dict[domicile]\n",
    "\n",
    "                            temp_a = a[((a[:,0] ) <= (l_start_int)) & ((a[:, 1] ) >= (l_end_int)) & (a[:, 2] <= l_p_cycle)]  \n",
    "                            num_feasible_blocks = len(temp_a)\n",
    "                            total_block_duration_length += sum(temp_a[:,3])\n",
    "                            \n",
    "        else: \n",
    "            if l_o in fc_domiciles: \n",
    "                for domicile in fc_domiciles[l_o]:\n",
    "                    if domicile in blocks_dict:\n",
    "                        a = blocks_dict[domicile]\n",
    "                        temp_a = a[((a[:,0]) <= (l_start_int)) & ((a[:, 1]) >= (l_end_int)) & (a[:, 2] <= l_p_cycle)] \n",
    "                        num_feasible_blocks = len(temp_a)\n",
    "                        total_block_duration_length += sum(temp_a[:,3])            \n",
    "            \n",
    "                       \n",
    "        loads_dict[(l_id,l_p_cycle)] = (num_feasible_blocks,total_block_duration_length)\n",
    "        \n",
    "    \n",
    "    if len(loads_dict) % 10000 == 0:\n",
    "        print(len(loads_dict))\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('done')\n",
    "        print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_loads_without_domicile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loads_without_domicile = loads[loads.load_id.isin(loads_without_domicile)]\n",
    "df_loads_without_domicile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['key'] = loads.apply(lambda row: (row['load_id'],row['creation_date_int']),axis = 1)\n",
    "\n",
    "df_items = []\n",
    "for k, v in loads_dict.items():\n",
    "    df_items.append((k, v[0], v[1]))\n",
    "loads_dict_df = pd.DataFrame(df_items,columns = ['key','num_feasible_blocks','total_block_minutes'])\n",
    "loads_dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = pd.merge(loads,loads_dict_df,on = 'key', how='left')\n",
    "loads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_blocks_data = loads[loads.num_feasible_blocks == 0]\n",
    "\n",
    "missing_blocks_data['first_checkin_time_utc'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(loads.num_feasible_blocks).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = loads[~loads.load_id.isin(loads_without_domicile)]\n",
    "print(len(xx))\n",
    "pd.Series(xx.planning_status_by_blocks.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loads we do not know the associated domicile info\n",
    "loads['has_domicile'] =  np.where(loads['load_id'].isin(loads_without_domicile),0,1)\n",
    "loads.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads[loads.has_domicile == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Data for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(loads.planning_status_by_blocks).value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads[~loads.origin_state.isin(US_STATES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads[~loads.dest_state.isin(US_STATES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = loads[loads.dest_state.isin(US_STATES)]\n",
    "loads = loads[loads.origin_state.isin(US_STATES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### remove loads that are canceled \n",
    "loads = loads[loads.canceled_load == False]\n",
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = loads[loads['load_cancellation_date'] == '2050-01-01 00:00:00']\n",
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(loads.load_cancellation_date.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(loads.num_feasible_blocks).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(loads.planning_status_by_blocks).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['is_eventually_unplanned'] = np.where(loads.planning_status_by_blocks == 'Planned in a block',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(loads['is_eventually_unplanned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(pd.to_datetime(loads.first_checkin_time_utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['lead_time_to_departure'] = (pd.to_datetime(loads.first_checkin_time_utc) - pd.to_datetime(loads.creation_date)).astype('timedelta64[h]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['lead_time_to_departure'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loads))\n",
    "loads = loads[loads['lead_time_to_departure'] > 0]\n",
    "print(len(loads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['lead_time_to_departure'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['load_id','r4c_adhoc','wims_load','enrichment_flag','rlb_load','planned_load','resource_block_id']\n",
    "planned_loads = loads[loads.is_eventually_unplanned == 0]\n",
    "planned_loads[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['num_feasible_blocks'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loads[loads['num_feasible_blocks'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Write the output ####\n",
    "loads.to_csv(data_dir +'teams_w_planned_blocks_total.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads['creation_date'] = pd.to_datetime(loads['creation_date']) \n",
    "loads['year'] = loads['creation_date'].dt.year\n",
    "loads['week'] = loads['creation_date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads2020 = loads[loads.year == 2020]\n",
    "loads2021 = loads[loads.year == 2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(loads2020))\n",
    "print(len(loads2021))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads1 = loads[(loads.year == 2020) & (loads.week <= 49)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads2 = loads[(loads.year == 2020) & (loads.week <= 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads3 = loads[(loads.year == 2020) & (loads.week <= 51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads4 = loads[(loads.year == 2020) & (loads.week <= 52)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads1.to_csv(data_dir +'train_49.csv', sep='\\t')\n",
    "loads2.to_csv(data_dir +'train_50.csv', sep='\\t')\n",
    "loads2.to_csv(data_dir +'train_51.csv', sep='\\t')\n",
    "loads4.to_csv(data_dir +'train_52.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads2020.to_csv(data_dir +'train_2020.csv', sep='\\t')\n",
    "loads2021.to_csv(data_dir +'train_2021.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
